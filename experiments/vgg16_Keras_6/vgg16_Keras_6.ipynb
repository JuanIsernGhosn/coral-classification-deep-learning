{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16_Keras_6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Vv25xKciEepB",
        "colab_type": "code",
        "outputId": "8df0d7d3-35b7-4e45-8cd8-282ba5058f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JuanIsernGhosn/coral-classification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'coral-classification' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "soFFmp4a-x2S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "experiment = \"coral-classification-deep-learning/experiments/vgg16_Keras_2/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2ZcplHO_Uya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import dtypes\n",
        "import numpy\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Activation, merge\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD, Adam\n",
        "import keras.backend as K\n",
        "from natsort import natsorted, ns\n",
        "import keras\n",
        "import PIL\n",
        "from keras.regularizers import l2\n",
        "from glob import glob\n",
        "from keras.applications import vgg16\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZQEB9usCecLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fijar las semillas\n",
        "seed = 2032 # Semilla del numpy\n",
        "tf.set_random_seed(seed)# Fijar semilla del keras/tensorflow\n",
        "\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "\n",
        "model_name = 'model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_NqWAC0CL7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train and test directories\n",
        "train_dir = \"coral-classification/coral_img/train/\"\n",
        "test_dir = \"coral-classification/coral_img/Test_Mixed/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7HiUjB1e8Cz",
        "colab_type": "code",
        "outputId": "14512a48-0ed4-427c-8461-30e6b8f137d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Classes\n",
        "clases = sorted(os.listdir(train_dir))\n",
        "print(clases)\n",
        "\n",
        "x_train = np.array([cv2.imread(os.path.join(train_dir, cl, name)) for cl in clases\n",
        "           for name in os.listdir(os.path.join(train_dir, cl))])\n",
        "y_train = np.array([n for n, cl in enumerate(clases)\n",
        "           for name in os.listdir(os.path.join(train_dir, cl))])\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train, y_train = x_train[idx], y_train[idx]\n",
        "\n",
        "test_files = natsorted(os.listdir(test_dir))\n",
        "\n",
        "x_test = np.array([cv2.imread(os.path.join(test_dir, name)) \n",
        "                   for name in test_files])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ACER', 'APAL', 'CNAT', 'DANT', 'DSTR', 'GORG', 'MALC', 'MCAV', 'MMEA', 'MONT', 'PALY', 'SPO', 'SSID', 'TUNI']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dRNhQRcFe_-i",
        "colab_type": "code",
        "outputId": "6e059c99-fa20-46b3-be07-2a5b852da15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train, dtype=int)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(len(clases))\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(620, 256, 256, 3)\n",
            "14\n",
            "(620, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wI4HZ23tf1-Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhNg9eqNgLip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = vgg16.VGG16(weights='imagenet',include_top=False, input_shape=(256,256,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "du8Eh-LqkYG8",
        "colab_type": "code",
        "outputId": "de56a47b-8560-4eaf-e9e7-da5bfc30ff6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Y8xutkmkQe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=base_model.output\n",
        "# x=Conv2D(512, (8, 8), activation='relu')(x)\n",
        "# x=MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x=Flatten()(x)\n",
        "# x=Dropout(rate=0.25)(x)\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 3\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(14,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model=Model(inputs=base_model.input, outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iYPSs4WQgi8o",
        "colab_type": "code",
        "outputId": "2b97fd08-9170-405e-987f-82d3d96e818f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_4\n",
            "1 block1_conv1\n",
            "2 block1_conv2\n",
            "3 block1_pool\n",
            "4 block2_conv1\n",
            "5 block2_conv2\n",
            "6 block2_pool\n",
            "7 block3_conv1\n",
            "8 block3_conv2\n",
            "9 block3_conv3\n",
            "10 block3_pool\n",
            "11 block4_conv1\n",
            "12 block4_conv2\n",
            "13 block4_conv3\n",
            "14 block4_pool\n",
            "15 block5_conv1\n",
            "16 block5_conv2\n",
            "17 block5_conv3\n",
            "18 block5_pool\n",
            "19 flatten_4\n",
            "20 dense_7\n",
            "21 dense_8\n",
            "22 dense_9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LlBXWTlah6qN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in model.layers[:19]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[19:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr=0.001), \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yMwIUfWoinE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_acc', mode='max', min_delta=0, patience=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKYLsn48i2UU",
        "colab_type": "code",
        "outputId": "cc4e1ac0-15cc-4f4e-82b0-37b36a1fafd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2247
        }
      },
      "cell_type": "code",
      "source": [
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size, subset=\"training\"),\n",
        "                   steps_per_epoch=int(len(x_train)*0.8) / batch_size, epochs=epochs,\n",
        "                   validation_data = datagen.flow(x_train, y_train, batch_size=batch_size, subset='validation'),\n",
        "                   validation_steps = int(len(x_train)*0.2) / batch_size,\n",
        "                   verbose=1, callbacks=[es])\n",
        "\n",
        "model.save(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "16/15 [==============================] - 14s 894ms/step - loss: 11.6468 - acc: 0.1541 - val_loss: 11.4646 - val_acc: 0.2419\n",
            "Epoch 2/1000\n",
            "16/15 [==============================] - 10s 640ms/step - loss: 12.7877 - acc: 0.1717 - val_loss: 11.7684 - val_acc: 0.2339\n",
            "Epoch 3/1000\n",
            "16/15 [==============================] - 10s 644ms/step - loss: 12.5857 - acc: 0.1952 - val_loss: 11.5979 - val_acc: 0.2661\n",
            "Epoch 4/1000\n",
            "16/15 [==============================] - 10s 636ms/step - loss: 12.2002 - acc: 0.2264 - val_loss: 11.0490 - val_acc: 0.2984\n",
            "Epoch 5/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 12.2957 - acc: 0.2228 - val_loss: 11.4579 - val_acc: 0.2742\n",
            "Epoch 6/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 12.2638 - acc: 0.2268 - val_loss: 11.4100 - val_acc: 0.2742\n",
            "Epoch 7/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 12.1664 - acc: 0.2384 - val_loss: 11.3404 - val_acc: 0.2903\n",
            "Epoch 8/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 12.1106 - acc: 0.2403 - val_loss: 11.3623 - val_acc: 0.2823\n",
            "Epoch 9/1000\n",
            "16/15 [==============================] - 10s 648ms/step - loss: 12.1300 - acc: 0.2343 - val_loss: 11.3761 - val_acc: 0.2903\n",
            "Epoch 10/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 12.0404 - acc: 0.2498 - val_loss: 11.3451 - val_acc: 0.2823\n",
            "Epoch 11/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 12.1368 - acc: 0.2246 - val_loss: 11.5694 - val_acc: 0.2581\n",
            "Epoch 12/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 12.1480 - acc: 0.2325 - val_loss: 11.2384 - val_acc: 0.2903\n",
            "Epoch 13/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 12.1282 - acc: 0.2322 - val_loss: 10.7787 - val_acc: 0.3226\n",
            "Epoch 14/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 11.0582 - acc: 0.2560 - val_loss: 7.1517 - val_acc: 0.1935\n",
            "Epoch 15/1000\n",
            "16/15 [==============================] - 10s 640ms/step - loss: 2.7047 - acc: 0.3339 - val_loss: 1.6084 - val_acc: 0.5081\n",
            "Epoch 16/1000\n",
            "16/15 [==============================] - 10s 637ms/step - loss: 1.1711 - acc: 0.6348 - val_loss: 1.5710 - val_acc: 0.5161\n",
            "Epoch 17/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 0.9159 - acc: 0.7050 - val_loss: 1.0224 - val_acc: 0.6694\n",
            "Epoch 18/1000\n",
            "16/15 [==============================] - 10s 640ms/step - loss: 0.5869 - acc: 0.8301 - val_loss: 0.7423 - val_acc: 0.7742\n",
            "Epoch 19/1000\n",
            "16/15 [==============================] - 10s 644ms/step - loss: 0.4910 - acc: 0.8202 - val_loss: 0.6703 - val_acc: 0.7823\n",
            "Epoch 20/1000\n",
            "16/15 [==============================] - 10s 641ms/step - loss: 0.3813 - acc: 0.8671 - val_loss: 0.8869 - val_acc: 0.7016\n",
            "Epoch 21/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 0.2536 - acc: 0.9238 - val_loss: 0.7462 - val_acc: 0.7661\n",
            "Epoch 22/1000\n",
            "16/15 [==============================] - 10s 636ms/step - loss: 0.2478 - acc: 0.9259 - val_loss: 0.7043 - val_acc: 0.8226\n",
            "Epoch 23/1000\n",
            "16/15 [==============================] - 10s 647ms/step - loss: 0.2650 - acc: 0.9084 - val_loss: 0.6690 - val_acc: 0.8065\n",
            "Epoch 24/1000\n",
            "16/15 [==============================] - 10s 641ms/step - loss: 0.2289 - acc: 0.9276 - val_loss: 0.4564 - val_acc: 0.8548\n",
            "Epoch 25/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 0.1530 - acc: 0.9550 - val_loss: 0.5621 - val_acc: 0.8548\n",
            "Epoch 26/1000\n",
            "16/15 [==============================] - 10s 635ms/step - loss: 0.1329 - acc: 0.9667 - val_loss: 0.5372 - val_acc: 0.7984\n",
            "Epoch 27/1000\n",
            "16/15 [==============================] - 10s 652ms/step - loss: 0.1277 - acc: 0.9552 - val_loss: 0.7011 - val_acc: 0.8226\n",
            "Epoch 28/1000\n",
            "16/15 [==============================] - 10s 644ms/step - loss: 0.1308 - acc: 0.9628 - val_loss: 0.6390 - val_acc: 0.8468\n",
            "Epoch 29/1000\n",
            "16/15 [==============================] - 10s 644ms/step - loss: 0.1057 - acc: 0.9746 - val_loss: 0.4797 - val_acc: 0.8387\n",
            "Epoch 30/1000\n",
            "16/15 [==============================] - 10s 649ms/step - loss: 0.0754 - acc: 0.9785 - val_loss: 0.4794 - val_acc: 0.8629\n",
            "Epoch 31/1000\n",
            "16/15 [==============================] - 10s 649ms/step - loss: 0.0844 - acc: 0.9804 - val_loss: 0.4265 - val_acc: 0.8629\n",
            "Epoch 32/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 0.0473 - acc: 0.9902 - val_loss: 0.4884 - val_acc: 0.8306\n",
            "Epoch 33/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 0.0479 - acc: 0.9863 - val_loss: 0.6456 - val_acc: 0.8145\n",
            "Epoch 34/1000\n",
            "16/15 [==============================] - 10s 647ms/step - loss: 0.0828 - acc: 0.9726 - val_loss: 0.5199 - val_acc: 0.8710\n",
            "Epoch 35/1000\n",
            "16/15 [==============================] - 10s 641ms/step - loss: 0.0649 - acc: 0.9806 - val_loss: 0.5305 - val_acc: 0.8629\n",
            "Epoch 36/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 0.0716 - acc: 0.9785 - val_loss: 0.5847 - val_acc: 0.8548\n",
            "Epoch 37/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 0.0571 - acc: 0.9843 - val_loss: 0.5192 - val_acc: 0.8387\n",
            "Epoch 38/1000\n",
            "16/15 [==============================] - 10s 641ms/step - loss: 0.0296 - acc: 0.9941 - val_loss: 0.6255 - val_acc: 0.8387\n",
            "Epoch 39/1000\n",
            "16/15 [==============================] - 10s 646ms/step - loss: 0.0656 - acc: 0.9726 - val_loss: 0.4745 - val_acc: 0.8468\n",
            "Epoch 40/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 0.0620 - acc: 0.9804 - val_loss: 0.6917 - val_acc: 0.7984\n",
            "Epoch 41/1000\n",
            "16/15 [==============================] - 10s 649ms/step - loss: 0.1059 - acc: 0.9648 - val_loss: 0.5337 - val_acc: 0.8790\n",
            "Epoch 42/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 0.0648 - acc: 0.9785 - val_loss: 0.6985 - val_acc: 0.8226\n",
            "Epoch 43/1000\n",
            "16/15 [==============================] - 10s 636ms/step - loss: 0.0922 - acc: 0.9688 - val_loss: 0.7369 - val_acc: 0.7903\n",
            "Epoch 44/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 0.2172 - acc: 0.9374 - val_loss: 0.6445 - val_acc: 0.8387\n",
            "Epoch 45/1000\n",
            "16/15 [==============================] - 10s 639ms/step - loss: 0.1251 - acc: 0.9473 - val_loss: 0.6244 - val_acc: 0.8145\n",
            "Epoch 46/1000\n",
            "16/15 [==============================] - 10s 644ms/step - loss: 0.0853 - acc: 0.9727 - val_loss: 0.5578 - val_acc: 0.7903\n",
            "Epoch 47/1000\n",
            "16/15 [==============================] - 10s 637ms/step - loss: 0.0428 - acc: 0.9883 - val_loss: 0.6415 - val_acc: 0.8548\n",
            "Epoch 48/1000\n",
            "16/15 [==============================] - 10s 636ms/step - loss: 0.0455 - acc: 0.9843 - val_loss: 0.5069 - val_acc: 0.8548\n",
            "Epoch 49/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 0.0315 - acc: 0.9903 - val_loss: 0.5635 - val_acc: 0.8387\n",
            "Epoch 50/1000\n",
            "16/15 [==============================] - 10s 645ms/step - loss: 0.0568 - acc: 0.9727 - val_loss: 0.4340 - val_acc: 0.9032\n",
            "Epoch 51/1000\n",
            "16/15 [==============================] - 10s 636ms/step - loss: 0.0563 - acc: 0.9824 - val_loss: 0.5612 - val_acc: 0.9032\n",
            "Epoch 52/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 0.0711 - acc: 0.9687 - val_loss: 0.8807 - val_acc: 0.7823\n",
            "Epoch 53/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 0.0697 - acc: 0.9706 - val_loss: 0.7360 - val_acc: 0.8710\n",
            "Epoch 54/1000\n",
            "16/15 [==============================] - 10s 630ms/step - loss: 0.0680 - acc: 0.9785 - val_loss: 0.5916 - val_acc: 0.8629\n",
            "Epoch 55/1000\n",
            "16/15 [==============================] - 10s 641ms/step - loss: 0.0359 - acc: 0.9942 - val_loss: 0.3496 - val_acc: 0.9032\n",
            "Epoch 56/1000\n",
            "16/15 [==============================] - 10s 647ms/step - loss: 0.0494 - acc: 0.9804 - val_loss: 0.7409 - val_acc: 0.8145\n",
            "Epoch 57/1000\n",
            "16/15 [==============================] - 10s 649ms/step - loss: 0.0850 - acc: 0.9687 - val_loss: 0.8072 - val_acc: 0.7903\n",
            "Epoch 58/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 0.1381 - acc: 0.9590 - val_loss: 0.8464 - val_acc: 0.8065\n",
            "Epoch 59/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 0.1236 - acc: 0.9706 - val_loss: 0.7241 - val_acc: 0.8145\n",
            "Epoch 60/1000\n",
            "16/15 [==============================] - 10s 649ms/step - loss: 0.0484 - acc: 0.9883 - val_loss: 0.5602 - val_acc: 0.8387\n",
            "Epoch 61/1000\n",
            "16/15 [==============================] - 10s 638ms/step - loss: 0.0418 - acc: 0.9902 - val_loss: 0.5081 - val_acc: 0.8952\n",
            "Epoch 62/1000\n",
            "16/15 [==============================] - 10s 643ms/step - loss: 0.0118 - acc: 0.9980 - val_loss: 0.4335 - val_acc: 0.9032\n",
            "Epoch 63/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 0.0245 - acc: 0.9863 - val_loss: 0.6204 - val_acc: 0.8710\n",
            "Epoch 64/1000\n",
            "16/15 [==============================] - 10s 642ms/step - loss: 0.0133 - acc: 0.9980 - val_loss: 0.4481 - val_acc: 0.8548\n",
            "Epoch 65/1000\n",
            "16/15 [==============================] - 10s 639ms/step - loss: 0.0189 - acc: 0.9922 - val_loss: 0.4653 - val_acc: 0.8952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zJqyqluISfEe",
        "colab_type": "code",
        "outputId": "bc30e270-de40-4225-9bee-3dd00908e939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predictions_test = model.predict(x_test, verbose=1)\n",
        "\n",
        "data = pd.DataFrame()\n",
        "data['Id'] = test_files\n",
        "data['Category'] = predictions_test.argmax(axis=-1)\n",
        "\n",
        "\n",
        "data.to_csv(\"envio.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146/146 [==============================] - 2s 14ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "62v--Nc3HJpa",
        "colab_type": "code",
        "outputId": "26590682-6536-43aa-c7ac-b077fb168804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "conversion = {\n",
        "    'a': 0,\n",
        "    'b': 1,\n",
        "    'c': 2,\n",
        "    'd': 3,\n",
        "    'e': 4,\n",
        "    'f': 5,\n",
        "    'g': 6,\n",
        "    'h': 7,\n",
        "    'i': 8,\n",
        "    'j': 9,\n",
        "    'k': 10,\n",
        "    'l': 11,\n",
        "    'm': 12,\n",
        "    'n': 13\n",
        "}\n",
        "classes = []\n",
        "for t in test_files:\n",
        "  class_ = t.split(\"T\")[0]\n",
        "  classes.append(conversion[class_])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(classes, data['Category']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8561643835616438\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}